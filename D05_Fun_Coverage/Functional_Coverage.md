Perfect ðŸ‘
Now we enter **Day-5: Functional Coverage** â€” this is the topic that **separates juniors from real verification engineers**.

Everything you wrote so far was preparation **for this day**.

---

# ðŸŸ¢ DAY-5 â€” FUNCTIONAL COVERAGE (SYSTEMVERILOG)

## ðŸŽ¯ Day-5 Goal

By the end of Day-5, you must be able to explain:

> â€œHow do you know your random tests are *good enough*?â€

Functional coverage answers that.

---

## 1ï¸âƒ£ What Functional Coverage IS (Conceptual)

Randomization answers:

> *What values did I generate?*

Coverage answers:

> *What behaviors did I actually test?*

Without coverage:

* Random â‰  complete
* Bugs hide silently

ðŸ“Œ **Golden interview line**:

> â€œRandom stimulus without functional coverage is blind verification.â€

---

## 2ï¸âƒ£ Code Coverage vs Functional Coverage (Very Important)

| Code Coverage       | Functional Coverage   |
| ------------------- | --------------------- |
| Tool-generated      | User-defined          |
| RTL-focused         | Spec-focused          |
| Statements/branches | Scenarios             |
| â€œDid code execute?â€ | â€œDid behavior occur?â€ |

ðŸ‘‰ DV engineers own **functional coverage**, not code coverage.

---

## 3ï¸âƒ£ Where Coverage Lives

Coverage belongs in:

* Testbench
* Monitor
* Checker
* NOT inside DUT

âœ” Same place as random stimulus
âœ” Same abstraction level

---

## 4ï¸âƒ£ Your First `covergroup` (Minimal & Correct)

Letâ€™s add coverage for your **DFF behavior**.

### Coverage goals:

* `en` = 0 and 1
* `d` = 0 and 1
* Valid `(en,d)` combinations

---

## 5ï¸âƒ£ Add This to Your TB (Minimal Change)

### ðŸ”¹ Step 1: Declare Covergroup

Add **inside `tb_dff`**:

```systemverilog
covergroup dff_cg @(posedge clk);
    coverpoint en {
        bins en_0 = {0};
        bins en_1 = {1};
    }

    coverpoint d {
        bins d_0 = {0};
        bins d_1 = {1};
    }

    cross en, d;
endgroup
```

ðŸ“Œ Sampling happens at `posedge clk` â€” exactly correct for sequential logic.

---

### ðŸ”¹ Step 2: Create Coverage Instance

Still inside `tb_dff`:

```systemverilog
dff_cg cg = new();
```

Thatâ€™s it. No manual sampling needed.

---

## 6ï¸âƒ£ Why This Is CORRECT

* Sampling aligned with clock
* Uses DUT-facing signals
* Cross automatically ignores illegal `(en=0,d=1)` because your stimulus never creates it

ðŸ“Œ You are measuring **what the DUT actually saw**.

---

## 7ï¸âƒ£ Run Simulation Again

```bash
xvlog -sv dff_c.sv tb_dff.sv
xelab tb_dff -debug typical
xsim tb_dff -runall
```

Simulation will run as before â€” coverage collects silently.

---

## 8ï¸âƒ£ How to View Coverage (Important)

After simulation:

```bash
xsim tb_dff
xsim> report_coverage
```

Youâ€™ll see:

* Coverpoint hit percentages
* Cross coverage numbers

ðŸ“Œ **100% coverage does NOT mean bug-free**
ðŸ“Œ **0% coverage means useless test**

---

## 9ï¸âƒ£ Expected Coverage Behavior

Given enough random cycles:

| Coverage Item | Expectation             |
| ------------- | ----------------------- |
| en            | 100%                    |
| d             | 100%                    |
| en Ã— d        | 75% (one illegal combo) |

Thatâ€™s **correct**, not a failure.

---

## ðŸ”Ÿ Common Beginner Mistakes (Avoid These)

âŒ Sampling on `@(*)`
âŒ Putting covergroups in DUT
âŒ Expecting coverage to increase without running simulation
âŒ Treating coverage as pass/fail
âŒ Ignoring cross coverage

---

## 1ï¸âƒ£1ï¸âƒ£ Interview Questions You Can Now Answer

* What is functional coverage?
* Difference between code & functional coverage?
* Why cross coverage is needed?
* Where do you sample coverage?
* Why 100% coverage is not always possible?

---

## ðŸ§ª Day-5 Mandatory Exercise

1. Add the covergroup above
2. Run simulation
3. Generate coverage report
4. Observe:

   * Which bins hit
   * Which bin is missing and WHY

---

## âœ… Day-5 Progress Check

When done, paste:

* Coverage report output (text)
  OR say:

> **â€œCoverage bins observed as expectedâ€**

Then we proceed to:

> **Day-6: Assertions (SVA) â€” this is BIG** ðŸš€
